{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahpo_train.learner import *\n",
    "from yahpo_train.metrics import *\n",
    "from yahpo_train.cont_scalers import *\n",
    "from yahpo_gym.benchmarks import lcbench, rbv2, nb301, fcnet, taskset, fcnet\n",
    "from yahpo_gym.configuration import cfg\n",
    "from fastai.callback.wandb import *\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a surrogate:\n",
    "\n",
    "We provide a function `fit_config` that allows for training a surrogate with a set of hyperparameters and the option to export the surrogate (this can overwrite existing surrogates!).\n",
    "\n",
    "A particularity is that we use a set of so called `ContTransformers` in order to transfer continuous variables to a scale better suited for optimization! \n",
    "This has a strong effect on the resulting performance and should therefore be optimized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_config(\n",
    "    key,\n",
    "    embds_dbl=None,\n",
    "    embds_tgt=None,\n",
    "    tfms=None,\n",
    "    lr=1e-4,\n",
    "    epochs=25,\n",
    "    frac=0.1,\n",
    "    bs=2048,\n",
    "    export=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fit function with hyperparameters\n",
    "    \"\"\"\n",
    "    cc = cfg(key)\n",
    "    dls = dl_from_config(cc, bs=bs, frac=frac)\n",
    "\n",
    "    # Construct embds from transforms. tfms overwrites emdbs_dbl, embds_tgt\n",
    "    if tfms is not None:\n",
    "        embds_dbl = [\n",
    "            tfms.get(name) if tfms.get(name) is not None else ContTransformerNone\n",
    "            for name, cont in dls.all_cols[dls.cont_names].iteritems()\n",
    "        ]\n",
    "        embds_tgt = [\n",
    "            tfms.get(name) if tfms.get(name) is not None else ContTransformerNone\n",
    "            for name, cont in dls.ys.iteritems()\n",
    "        ]\n",
    "\n",
    "    # Instantiate learner\n",
    "    f = ResNet(dls, embds_dbl=embds_dbl, embds_tgt=embds_tgt)\n",
    "    l = SurrogateTabularLearner(\n",
    "        dls, f, loss_func=nn.MSELoss(reduction=\"mean\"), metrics=nn.MSELoss\n",
    "    )\n",
    "    l.metrics = [AvgTfedMetric(mae), AvgTfedMetric(r2), AvgTfedMetric(spearman)]\n",
    "    l.add_cb(MixHandler)\n",
    "    l.add_cb(EarlyStoppingCallback(patience=3))\n",
    "\n",
    "    # Fit\n",
    "    l.fit_flat_cos(epochs, lr)\n",
    "\n",
    "    if export:\n",
    "        l.export_onnx(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: NasBench 301\n",
    "Find an example for training the `NASBENCH 301` surrogate below:\n",
    "\n",
    "We supply a list of `ContTransformer`'s to our `fit_config` function that define the specific transformers that should be applied for this scenario:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nb301(key=\"nb301\", **kwargs):\n",
    "    embds_dbl = [partial(ContTransformerMultScalar, m=1 / 52)]\n",
    "    embds_tgt = [partial(ContTransformerMultScalar, m=1 / 100), ContTransformerRange]\n",
    "    fit_config(key, embds_dbl=embds_dbl, embds_tgt=embds_tgt, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: rbv2_super\n",
    "\n",
    "A more involved example is the `rbv2_super` surrogate, where multiple different transformers are used depending on the input and output variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rbv2_super(key=\"rbv2_super\", **kwargs):\n",
    "    # Transforms\n",
    "    tfms = {}\n",
    "    [\n",
    "        tfms.update({k: ContTransformerRange})\n",
    "        for k in [\n",
    "            \"mmce\",\n",
    "            \"f1\",\n",
    "            \"auc\",\n",
    "            \"aknn.k\",\n",
    "            \"aknn.M\",\n",
    "            \"rpart.maxdepth\",\n",
    "            \"rpart.minsplit\",\n",
    "            \"rpart.minbucket\",\n",
    "            \"xgboost.max_depth\",\n",
    "        ]\n",
    "    ]\n",
    "    [\n",
    "        tfms.update({k: partial(ContTransformerLogRange)})\n",
    "        for k in [\"timetrain\", \"timepredict\", \"svm.cost\", \"svm.gamma\"]\n",
    "    ]\n",
    "    [\n",
    "        tfms.update(\n",
    "            {k: partial(ContTransformerLogRange, logfun=torch.log2, expfun=torch.exp2)}\n",
    "        )\n",
    "        for k in [\n",
    "            \"glmnet.s\",\n",
    "            \"rpart.cp\",\n",
    "            \"aknn.ef\",\n",
    "            \"aknn.ef_construction\",\n",
    "            \"xgboost.nrounds\",\n",
    "            \"xgboost.eta\",\n",
    "            \"xgboost.gamma\",\n",
    "            \"xgboost.lambda\",\n",
    "            \"xgboost.alpha\",\n",
    "            \"xgboost.min_child_weight\",\n",
    "            \"ranger.num.trees\",\n",
    "            \"ranger.min.node.size\",\n",
    "            \"ranger.num.random.splits\",\n",
    "        ]\n",
    "    ]\n",
    "    [tfms.update({k: ContTransformerNegExpRange}) for k in [\"logloss\"]]\n",
    "\n",
    "    fit_config(key, tfms=tfms, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = cfg(\"fcnet\")\n",
    "\n",
    "b = BenchmarkSet(\"fcnet\")\n",
    "\n",
    "b.config_space.get_hyperparameter_names() == cc.hp_names"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "935079f3ab4b06ec76910fd5af9cfadee87e8a756fe17d7789065f69c1782d29"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
