{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using YAHPO Gym: A quick introduction\n",
    "\n",
    "Using YAHPO GYM we can benchmark a new Hyperparameter optimization method on a large amount of problems in a very short time-frame.\n",
    "\n",
    "This tutorial walks us through the core concepts and functionality of ``yahpo_gym` and showscases a practical example.\n",
    "\n",
    "YAHPO GYM consists of several `scenarios`, e.g. the collection of all benchmark instances in `lcbench` is a `scenario`.\n",
    "An `instance` is the concrete task of optimizing hyperparameters of the neural network on a given dataset from OpenML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core functionality: Configuration & BenchmarkSet\n",
    "\n",
    "We first a have a brief look at at the two core classes we will make use of in `YAHPO GYM`: \n",
    "- A `Configuration` contains all relevant infos regarding a specific benchmarking scenario e.g. `lcbench`. We can load configurations with the `cfg(<key>)` shortcut.\n",
    "- A `BenchmarkSet` can be instantiated using a Configuration (or it's key) and contains the logic used to evaluate the surrogate model for a given query hyperparameter configuration (or set thereof).b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To run a benchmark you need to download the ONNX model (`new_model.onnx`), [ConfigSpace](https://automl.github.io/ConfigSpace/) (`config_space.json`) and some encoding info (`encoding.json`).\n",
    "\n",
    "You can download these [here](https://syncandshare.lrz.de/getlink/fiCMkzqj1bv1LfCUyvZKmLvd/), but **YAHPO GYM** can also autmatically download this for you.\n",
    "\n",
    "You should pertain the folder structure as on the hosting site (i.e., create a `\"path-to-data\"` directory, for example named `\"multifidelity_data\"`, containing the individual, e.g., `\"lcench\"`, directories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the local config & set path for surrogates and metadata\n",
    "from yahpo_gym import local_config\n",
    "local_config.init_config()\n",
    "local_config.set_data_path(\"~/yahpo_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# We first load the dict of configurations and the concrete benchmarks\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from yahpo_gym.configuration import cfg\n",
    "import yahpo_gym.benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can print a list of available configurations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And instantiate a Configuration using a key.\n",
    "conf_lcb = cfg('lcbench')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can download all required files using `download_files`.\n",
    "# Files will be downloaded to the data_path (\"~/yahpo_models\") set above.\n",
    "conf_lcb.download_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to query several important properties of the benchmark problem:\n",
    "\n",
    "- config_id : The id / key of the configuration\n",
    "- y_names  : The names of the target variables included in the surrogate model\n",
    "- hp_names: The names of all hyperparameters\n",
    "- cat_names : The names of categorical hyperparameters\n",
    "- cont_names  :  The names of continuous hyperparameters\n",
    "- fidelity_params  : The name of the fidelity parameter(s)\n",
    "- instance_names : The column pertaining to the available instances in a dataset\n",
    "- runtime_name : The name of parameters remeasuring runtime of  the model. \n",
    "- data : A `pandas` `DataFrame` containing the data used to train the surrogates. Only available if the data was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'val_accuracy',\n",
       " 'val_cross_entropy',\n",
       " 'val_balanced_accuracy',\n",
       " 'test_cross_entropy',\n",
       " 'test_balanced_accuracy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can for example query the target outputs of our surrogate:\n",
    "conf_lcb.y_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BemchmarkSet\n",
    "\n",
    "A benchmark set allows us to evaluate the surrogate models for a given configuration.\n",
    "We can instantiate them similarly to a `Configuration` using the **key**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkInstance (lcbench)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yahpo_gym import benchmark_set\n",
    "# Select a Benchmark\n",
    "bench = benchmark_set.BenchmarkSet(\"lcbench\")\n",
    "bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can again be used to query relevant meta-information:\n",
    "- instances: The available instances (in this case OpenML Task Id's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basedir': Path('/home/lps/yahpo_models'),\n",
       " 'download_url': 'https://syncandshare.lrz.de/dl/fiCMkzqj1bv1LfCUyvZKmLvd',\n",
       " 'config_id': 'lcbench',\n",
       " 'model': 'new_model.onnx',\n",
       " 'dataset': 'data.csv',\n",
       " 'config_space': 'config_space.json',\n",
       " 'encoding': 'encoding.json',\n",
       " 'y_names': ['time',\n",
       "  'val_accuracy',\n",
       "  'val_cross_entropy',\n",
       "  'val_balanced_accuracy',\n",
       "  'test_cross_entropy',\n",
       "  'test_balanced_accuracy'],\n",
       " 'cont_names': ['epoch',\n",
       "  'batch_size',\n",
       "  'learning_rate',\n",
       "  'momentum',\n",
       "  'weight_decay',\n",
       "  'num_layers',\n",
       "  'max_units',\n",
       "  'max_dropout'],\n",
       " 'cat_names': ['OpenML_task_id'],\n",
       " 'fidelity_params': ['epoch'],\n",
       " 'runtime_name': 'time',\n",
       " 'model_old': 'model.onnx',\n",
       " 'y_minimize': [True, False, True, False, True, False],\n",
       " 'instance_names': 'OpenML_task_id'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg(\"lcbench\").config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3945', '7593', '34539', '126025', '126026']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List available instances\n",
    "bench.instances[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now set an instance, this defines the instance (i.e. concrete dataset) to be evaluated.\n",
    "We can furthermore use the included `ConfigSpace` in order to sample a concrete configuration and evaluate it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 1.0176891, 'val_accuracy': 96.08849, 'val_cross_entropy': 0.36274177, 'val_balanced_accuracy': 0.533724, 'test_cross_entropy': 0.5219554, 'test_balanced_accuracy': 0.53069955}\n"
     ]
    }
   ],
   "source": [
    "# Set an instance\n",
    "bench.set_instance(\"3945\")\n",
    "# Sample a point from the configspace (containing parameters for the instance and budget)\n",
    "value = bench.config_space.sample_configuration(1).get_dictionary()\n",
    "# Evaluate\n",
    "print(bench.objective_function(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OpenML_task_id': '3945',\n",
       " 'batch_size': 33,\n",
       " 'epoch': 29,\n",
       " 'learning_rate': 0.004109761904272161,\n",
       " 'max_dropout': 0.23517516037170827,\n",
       " 'max_units': 65.27423374909003,\n",
       " 'momentum': 0.27385920624918386,\n",
       " 'num_layers': 4,\n",
       " 'weight_decay': 0.06160935519075886}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    OpenML_task_id, Type: Constant, Value: 3945\n",
       "    batch_size, Type: UniformInteger, Range: [16, 512], Default: 91, on log-scale\n",
       "    learning_rate, Type: UniformFloat, Range: [0.00010000000000000009, 0.10000000000000002], Default: 0.0031622777, on log-scale\n",
       "    max_dropout, Type: UniformFloat, Range: [0.0, 1.0], Default: 0.5\n",
       "    max_units, Type: UniformFloat, Range: [63.99999999999998, 1024.0], Default: 256.0, on log-scale\n",
       "    momentum, Type: UniformFloat, Range: [0.1, 0.99], Default: 0.545\n",
       "    num_layers, Type: UniformInteger, Range: [1, 5], Default: 3\n",
       "    weight_decay, Type: UniformFloat, Range: [1e-05, 0.1], Default: 0.050005"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the corresponding space we optimize over.\n",
    "bench.get_opt_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A working example\n",
    "\n",
    "In order to demonstrate using YAHPO Gym more in-depth we provide a full example benchmarking `HPBandSter` on an `lcbench` task.\n",
    "We again start by importing the relevant modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahpo_gym import benchmark_set\n",
    "import yahpo_gym.benchmarks.lcbench\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a worker class as required by `HPBandSter` that internally calls our `objective_function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpbandster.core.worker import Worker\n",
    "import hpbandster.core.nameserver as hpns\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "\n",
    "class lcbench(Worker):\n",
    "\n",
    "    def __init__(self, *args, sleep_interval=0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.bench = bench\n",
    "        self.sleep_interval = sleep_interval\n",
    "\n",
    "    def compute(self, config, budget, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config: dictionary containing the sampled configurations by the optimizer\n",
    "            budget: (float) amount of epochs the model can use to train\n",
    "\n",
    "        Returns:\n",
    "            dictionary with mandatory fields:\n",
    "                \"loss\" (scalar)\n",
    "                \"info\" (dict)\n",
    "        \"\"\"\n",
    "\n",
    "        config.update({\"epoch\": int(np.round(budget))})  # update epoch\n",
    "        result = bench.objective_function(config)  # evaluate\n",
    "\n",
    "        time.sleep(self.sleep_interval)\n",
    "\n",
    "        return({\n",
    "                    \"loss\": - float(result.get(\"val_accuracy\")),  # we want to maximize validation accuracy\n",
    "                    \"info\": \"empty\"\n",
    "                })\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "        # sets OpenML_task_id constant to \"3945\" and removes the epoch fidelity parameter\n",
    "        cs = bench.get_opt_space(instance = \"3945\", drop_fidelity_params = True)\n",
    "        return(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this worker class, we can now run the full benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:34:58 wait_for_workers trying to get the condition\n",
      "18:34:58 DISPATCHER: started the 'discover_worker' thread\n",
      "18:34:58 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f906d6d6908; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "18:34:58 DISPATCHER: started the 'job_runner' thread\n",
      "18:34:58 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "18:34:58 WORKER: start listening for jobs\n",
      "18:34:58 DISPATCHER: Pyro daemon running on localhost:38707\n",
      "18:34:58 DISPATCHER: Starting worker discovery\n",
      "18:34:58 DISPATCHER: Found 1 potential workers, 0 currently in the pool.\n",
      "18:34:58 DISPATCHER: discovered new worker, hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:58 HBMASTER: number of workers changed to 1\n",
      "18:34:58 Enough workers to start this run!\n",
      "18:34:58 HBMASTER: starting run at 1632933298.880362\n",
      "18:34:58 adjust_queue_size: lock accquired\n",
      "18:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:58 HBMASTER: adjusted queue size to (0, 1)\n",
      "18:34:58 DISPATCHER: Finished worker discovery\n",
      "18:34:58 start sampling a new configuration.\n",
      "18:34:58 DISPATCHER: Trying to submit another job.\n",
      "18:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:58 done sampling a new configuration.\n",
      "18:34:58 HBMASTER: schedule new run for iteration 0\n",
      "18:34:58 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "18:34:58 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "18:34:58 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "18:34:58 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:58 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "18:34:58 DISPATCHER: Trying to submit another job.\n",
      "18:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:58 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:58 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:58 WORKER: start processing job (0, 0, 0)\n",
      "18:34:58 WORKER: args: ()\n",
      "18:34:58 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 74, 'learning_rate': 0.03730364728284649, 'max_dropout': 0.10928899279517446, 'max_units': 352.7361539760635, 'momentum': 0.6132073024377236, 'num_layers': 1, 'weight_decay': 0.04487797472390004}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:58 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "18:34:58 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "18:34:58 DISPATCHER: job (0, 0, 0) finished\n",
      "18:34:58 DISPATCHER: register_result: lock acquired\n",
      "18:34:58 DISPATCHER: job (0, 0, 0) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:58 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 74, 'learning_rate': 0.03730364728284649, 'max_dropout': 0.10928899279517446, 'max_units': 352.7361539760635, 'momentum': 0.6132073024377236, 'num_layers': 1, 'weight_decay': 0.04487797472390004}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -73.41557312011719, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:58 job_callback for (0, 0, 0) started\n",
      "18:34:58 DISPATCHER: Trying to submit another job.\n",
      "18:34:58 job_callback for (0, 0, 0) got condition\n",
      "18:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:58 Only 1 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:58 HBMASTER: Trying to run another job!\n",
      "18:34:58 job_callback for (0, 0, 0) finished\n",
      "18:34:58 start sampling a new configuration.\n",
      "18:34:58 done sampling a new configuration.\n",
      "18:34:58 HBMASTER: schedule new run for iteration 0\n",
      "18:34:58 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "18:34:58 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "18:34:58 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "18:34:58 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:58 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "18:34:58 DISPATCHER: Trying to submit another job.\n",
      "18:34:58 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:58 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:58 WORKER: start processing job (0, 0, 1)\n",
      "18:34:58 WORKER: args: ()\n",
      "18:34:58 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 31, 'learning_rate': 0.08518909658125563, 'max_dropout': 0.3058476368770261, 'max_units': 863.0596531269018, 'momentum': 0.5368413097989411, 'num_layers': 4, 'weight_decay': 0.08674342468960657}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 1) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 1) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 31, 'learning_rate': 0.08518909658125563, 'max_dropout': 0.3058476368770261, 'max_units': 863.0596531269018, 'momentum': 0.5368413097989411, 'num_layers': 4, 'weight_decay': 0.08674342468960657}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -89.8255386352539, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 1) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 job_callback for (0, 0, 1) got condition\n",
      "18:34:59 Only 2 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 1) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: start processing job (0, 0, 2)\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.00013186846924119304, 'max_dropout': 0.5978682680734122, 'max_units': 408.45051767218047, 'momentum': 0.2511205608534902, 'num_layers': 2, 'weight_decay': 0.00969841062711537}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 2) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 2) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.00013186846924119304, 'max_dropout': 0.5978682680734122, 'max_units': 408.45051767218047, 'momentum': 0.2511205608534902, 'num_layers': 2, 'weight_decay': 0.00969841062711537}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -83.3320541381836, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 2) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 2) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:34:59 Only 3 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 2) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 3) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 3) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 3)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 3) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 3)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 237, 'learning_rate': 0.00024492005087955776, 'max_dropout': 0.9326481248593591, 'max_units': 113.13893756583592, 'momentum': 0.9549199898172877, 'num_layers': 1, 'weight_decay': 0.09036770277766405}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 3), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 3) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 3) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 3)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 237, 'learning_rate': 0.00024492005087955776, 'max_dropout': 0.9326481248593591, 'max_units': 113.13893756583592, 'momentum': 0.9549199898172877, 'num_layers': 1, 'weight_decay': 0.09036770277766405}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -54.900211334228516, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 3) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 3) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 Only 4 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 3) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 4) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 4) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 4)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 4) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 4)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 78, 'learning_rate': 0.00046605090102701046, 'max_dropout': 0.37760916609240414, 'max_units': 587.3005176686662, 'momentum': 0.6243512031363482, 'num_layers': 1, 'weight_decay': 0.059068870099834976}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 4), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 4) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 4) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 4)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 78, 'learning_rate': 0.00046605090102701046, 'max_dropout': 0.37760916609240414, 'max_units': 587.3005176686662, 'momentum': 0.6243512031363482, 'num_layers': 1, 'weight_decay': 0.059068870099834976}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -65.18270111083984, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 4) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 4) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 Only 5 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 4) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 5)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 204, 'learning_rate': 0.0009627007136968641, 'max_dropout': 0.142632116942372, 'max_units': 114.05559626681749, 'momentum': 0.5835428375685867, 'num_layers': 2, 'weight_decay': 0.04777656152782972}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 5) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 5) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 204, 'learning_rate': 0.0009627007136968641, 'max_dropout': 0.142632116942372, 'max_units': 114.05559626681749, 'momentum': 0.5835428375685867, 'num_layers': 2, 'weight_decay': 0.04777656152782972}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -56.33314895629883, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 5) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 job_callback for (0, 0, 5) got condition\n",
      "18:34:59 Only 6 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 5) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 6) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 6) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 6)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 6) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 159, 'learning_rate': 0.0007794238351845806, 'max_dropout': 0.6177280454429146, 'max_units': 284.36286806012544, 'momentum': 0.5467757478844134, 'num_layers': 4, 'weight_decay': 0.015343310867126706}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 6), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 6) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 6) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 6)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 159, 'learning_rate': 0.0007794238351845806, 'max_dropout': 0.6177280454429146, 'max_units': 284.36286806012544, 'momentum': 0.5467757478844134, 'num_layers': 4, 'weight_decay': 0.015343310867126706}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -70.55464935302734, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 6) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 6) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 Only 7 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 6) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 7) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 7) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 7)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 7) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 7)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 36, 'learning_rate': 0.00021079792907783103, 'max_dropout': 0.5959221435701585, 'max_units': 240.71839254970942, 'momentum': 0.5984560177688396, 'num_layers': 1, 'weight_decay': 0.035851791962409875}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 7), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 7) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 7) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 7)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 36, 'learning_rate': 0.00021079792907783103, 'max_dropout': 0.5959221435701585, 'max_units': 240.71839254970942, 'momentum': 0.5984560177688396, 'num_layers': 1, 'weight_decay': 0.035851791962409875}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -75.0745620727539, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 7) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 7) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 Only 8 run(s) for budget 1.925926 available, need more than 10 -> can't build model!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 7) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 8) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 8) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 8)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 8) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 8)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 71, 'learning_rate': 0.014713102434385998, 'max_dropout': 0.873979425795715, 'max_units': 824.7270685616847, 'momentum': 0.4719015589397174, 'num_layers': 3, 'weight_decay': 0.02998264085755615}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 8), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 8) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 8) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 8) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 8)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 71, 'learning_rate': 0.014713102434385998, 'max_dropout': 0.873979425795715, 'max_units': 824.7270685616847, 'momentum': 0.4719015589397174, 'num_layers': 3, 'weight_decay': 0.02998264085755615}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -86.63052368164062, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 8) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 job_callback for (0, 0, 8) got condition\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 8) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 9) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 9) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 9)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 9) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: start processing job (0, 0, 9)\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 19, 'learning_rate': 0.00015449907446589309, 'max_dropout': 0.8804425293712883, 'max_units': 930.1749596596248, 'momentum': 0.5586153493012914, 'num_layers': 2, 'weight_decay': 0.07750174375517623}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 9), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 9) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 9) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 9) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 9)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 19, 'learning_rate': 0.00015449907446589309, 'max_dropout': 0.8804425293712883, 'max_units': 930.1749596596248, 'momentum': 0.5586153493012914, 'num_layers': 2, 'weight_decay': 0.07750174375517623}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -86.13573455810547, 'info': 'empty'}\n",
      "exception: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:34:59 job_callback for (0, 0, 9) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 9) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 9) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 10)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 16, 'learning_rate': 0.09965246178024781, 'max_dropout': 0.23067079670548118, 'max_units': 186.01073772788814, 'momentum': 0.41038774349217866, 'num_layers': 3, 'weight_decay': 0.0017807843726372486}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 10) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 10) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 16, 'learning_rate': 0.09965246178024781, 'max_dropout': 0.23067079670548118, 'max_units': 186.01073772788814, 'momentum': 0.41038774349217866, 'num_layers': 3, 'weight_decay': 0.0017807843726372486}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -91.82847595214844, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 10) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 job_callback for (0, 0, 10) got condition\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 10) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 11) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 11) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 11)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 11) submitted to dispatcher\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 11)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 39, 'learning_rate': 0.06159566555411365, 'max_dropout': 0.6594305750936577, 'max_units': 387.8333454634667, 'momentum': 0.13364376917889323, 'num_layers': 2, 'weight_decay': 0.03236163152914593}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 11), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 11) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 11) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 11) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 11)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 39, 'learning_rate': 0.06159566555411365, 'max_dropout': 0.6594305750936577, 'max_units': 387.8333454634667, 'momentum': 0.13364376917889323, 'num_layers': 2, 'weight_decay': 0.03236163152914593}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -85.99544525146484, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 11) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 11) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 11) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 12) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 12) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 12)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 12) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: start processing job (0, 0, 12)\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 335, 'learning_rate': 0.00011061494140521067, 'max_dropout': 0.9851954432898017, 'max_units': 903.5368553186127, 'momentum': 0.6350123613602908, 'num_layers': 2, 'weight_decay': 0.09060836839847441}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 12), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 12) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 12) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 12)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 335, 'learning_rate': 0.00011061494140521067, 'max_dropout': 0.9851954432898017, 'max_units': 903.5368553186127, 'momentum': 0.6350123613602908, 'num_layers': 2, 'weight_decay': 0.09060836839847441}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -55.86240768432617, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 12) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 job_callback for (0, 0, 12) got condition\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 12) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 13) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 13) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 13)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 13) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 13)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 86, 'learning_rate': 0.006589518223952934, 'max_dropout': 0.8451177276334075, 'max_units': 205.2164637516088, 'momentum': 0.44951073668224517, 'num_layers': 3, 'weight_decay': 0.028528629600967963}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 13), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 13) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 13) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 13)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 86, 'learning_rate': 0.006589518223952934, 'max_dropout': 0.8451177276334075, 'max_units': 205.2164637516088, 'momentum': 0.44951073668224517, 'num_layers': 3, 'weight_decay': 0.028528629600967963}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -81.72071838378906, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 13) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 13) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 13) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 14) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 14) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 14)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 14) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 14)\n",
      "18:34:59 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 26, 'learning_rate': 0.0001700082178346727, 'max_dropout': 0.600748282711434, 'max_units': 151.34593278717193, 'momentum': 0.23535414523187556, 'num_layers': 3, 'weight_decay': 0.09830660897204233}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 14), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 14) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 14) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 14) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 14)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 26, 'learning_rate': 0.0001700082178346727, 'max_dropout': 0.600748282711434, 'max_units': 151.34593278717193, 'momentum': 0.23535414523187556, 'num_layers': 3, 'weight_decay': 0.09830660897204233}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -83.2768783569336, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 14) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 job_callback for (0, 0, 14) got condition\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 HBMASTER: Trying to run another job!\n",
      "18:34:59 job_callback for (0, 0, 14) finished\n",
      "18:34:59 start sampling a new configuration.\n",
      "18:34:59 done sampling a new configuration.\n",
      "18:34:59 HBMASTER: schedule new run for iteration 0\n",
      "18:34:59 HBMASTER: trying submitting job (0, 0, 15) to dispatcher\n",
      "18:34:59 HBMASTER: submitting job (0, 0, 15) to dispatcher\n",
      "18:34:59 DISPATCHER: trying to submit job (0, 0, 15)\n",
      "18:34:59 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:34:59 HBMASTER: job (0, 0, 15) submitted to dispatcher\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:34:59 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:34:59 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:34:59 WORKER: start processing job (0, 0, 15)\n",
      "18:34:59 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:34:59 WORKER: args: ()\n",
      "18:34:59 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 22, 'learning_rate': 0.06763257085268942, 'max_dropout': 0.658174270541606, 'max_units': 788.69514310382, 'momentum': 0.4423175410094665, 'num_layers': 3, 'weight_decay': 0.04003082477596873}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:34:59 WORKER: done with job (0, 0, 15), trying to register it.\n",
      "18:34:59 WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "18:34:59 DISPATCHER: job (0, 0, 15) finished\n",
      "18:34:59 DISPATCHER: register_result: lock acquired\n",
      "18:34:59 DISPATCHER: job (0, 0, 15) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:34:59 job_id: (0, 0, 15)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 22, 'learning_rate': 0.06763257085268942, 'max_dropout': 0.658174270541606, 'max_units': 788.69514310382, 'momentum': 0.4423175410094665, 'num_layers': 3, 'weight_decay': 0.04003082477596873}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -90.9416275024414, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:34:59 job_callback for (0, 0, 15) started\n",
      "18:34:59 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:34:59 job_callback for (0, 0, 15) got condition\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 15) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 16) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 16) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 16)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 16) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: start processing job (0, 0, 16)\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 71, 'learning_rate': 0.05256808336132757, 'max_dropout': 0.970224887967548, 'max_units': 333.29107731056337, 'momentum': 0.11127046618091352, 'num_layers': 3, 'weight_decay': 0.09916214131942899}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 16), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 16) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 16) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 16) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 16)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 71, 'learning_rate': 0.05256808336132757, 'max_dropout': 0.970224887967548, 'max_units': 333.29107731056337, 'momentum': 0.11127046618091352, 'num_layers': 3, 'weight_decay': 0.09916214131942899}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -84.9318618774414, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 16) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 job_callback for (0, 0, 16) got condition\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 16) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 17) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 17) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 17)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 17) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 WORKER: start processing job (0, 0, 17)\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 89, 'learning_rate': 0.006700784221568951, 'max_dropout': 0.2876804285667456, 'max_units': 641.0028644726066, 'momentum': 0.441791642606282, 'num_layers': 4, 'weight_decay': 0.07588250516594106}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 17), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 17) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 17) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 17) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 17)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 89, 'learning_rate': 0.006700784221568951, 'max_dropout': 0.2876804285667456, 'max_units': 641.0028644726066, 'momentum': 0.441791642606282, 'num_layers': 4, 'weight_decay': 0.07588250516594106}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -82.39381408691406, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 17) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 job_callback for (0, 0, 17) got condition\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:00 done building a new model for budget 1.925926 based on 9/15 split\n",
      "Best loss for this budget:-91.828476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 17) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 18) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 18) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 18)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 18) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: start processing job (0, 0, 18)\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 104, 'learning_rate': 0.000627729709886735, 'max_dropout': 0.9090119444446737, 'max_units': 549.6576932759838, 'momentum': 0.8602032418902146, 'num_layers': 2, 'weight_decay': 0.03431506731273006}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 18), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 18) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 18) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 18) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 18)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 104, 'learning_rate': 0.000627729709886735, 'max_dropout': 0.9090119444446737, 'max_units': 549.6576932759838, 'momentum': 0.8602032418902146, 'num_layers': 2, 'weight_decay': 0.03431506731273006}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -73.2635269165039, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 18) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 job_callback for (0, 0, 18) got condition\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:00 done building a new model for budget 1.925926 based on 9/16 split\n",
      "Best loss for this budget:-91.828476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 18) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 WORKER: start processing job (0, 0, 19)\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 18, 'learning_rate': 0.0028563496186187836, 'max_dropout': 0.9095926139180639, 'max_units': 235.0259346639654, 'momentum': 0.46355590683296066, 'num_layers': 3, 'weight_decay': 0.03296613067337738}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 19) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 19) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 18, 'learning_rate': 0.0028563496186187836, 'max_dropout': 0.9095926139180639, 'max_units': 235.0259346639654, 'momentum': 0.46355590683296066, 'num_layers': 3, 'weight_decay': 0.03296613067337738}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -89.22040557861328, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 19) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:00 job_callback for (0, 0, 19) got condition\n",
      "18:35:00 done building a new model for budget 1.925926 based on 9/17 split\n",
      "Best loss for this budget:-91.828476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 19) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 20) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 20) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 20)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 20) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 WORKER: start processing job (0, 0, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 142, 'learning_rate': 0.05199835635916993, 'max_dropout': 0.647005680388937, 'max_units': 106.99001089522743, 'momentum': 0.328723722606558, 'num_layers': 5, 'weight_decay': 0.09574665904617781}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 20), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 20) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 20) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 20) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 20)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 142, 'learning_rate': 0.05199835635916993, 'max_dropout': 0.647005680388937, 'max_units': 106.99001089522743, 'momentum': 0.328723722606558, 'num_layers': 5, 'weight_decay': 0.09574665904617781}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -77.09451293945312, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 20) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 job_callback for (0, 0, 20) got condition\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:00 done building a new model for budget 1.925926 based on 9/17 split\n",
      "Best loss for this budget:-91.828476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 20) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 best_vector: [0.001069854603775247, 0.12309155019814308, 0.46418693151074397, 0.46512243238328044, 0.845936680733598, 0.23944632852610717, 0.4402641280682722, 0.07526019268760255], 0.00994489589277848, 766.8842711432985, 7.626584238329407\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 21) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 21) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 21)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 21) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 WORKER: start processing job (0, 0, 21)\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 24, 'learning_rate': 0.00246922573425061, 'max_dropout': 0.46512243238328044, 'max_units': 668.019646538948, 'momentum': 0.3131072323882354, 'num_layers': 3, 'weight_decay': 0.007535266666833379}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 21), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 21) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 21) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 21) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 21)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 24, 'learning_rate': 0.00246922573425061, 'max_dropout': 0.46512243238328044, 'max_units': 668.019646538948, 'momentum': 0.3131072323882354, 'num_layers': 3, 'weight_decay': 0.007535266666833379}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -88.11693572998047, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 21) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:00 job_callback for (0, 0, 21) got condition\n",
      "18:35:00 done building a new model for budget 1.925926 based on 9/18 split\n",
      "Best loss for this budget:-91.828476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 21) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 best_vector: [0.002475945172961845, 0.16138759726664098, 0.513160353718648, 0.9764147590757396, 0.7412653340765627, 0.4930224509898522, 0.14880380403525395, 0.925872750677044], 0.05544907046980034, 10.880375365040543, 0.6033067003540127\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 22) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 22) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 22)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 22) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: start processing job (0, 0, 22)\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 27, 'learning_rate': 0.0034632278173121343, 'max_dropout': 0.9764147590757396, 'max_units': 499.74950795995755, 'momentum': 0.5387899813809685, 'num_layers': 1, 'weight_decay': 0.09258801634019763}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:00 WORKER: done with job (0, 0, 22), trying to register it.\n",
      "18:35:00 WORKER: registered result for job (0, 0, 22) with dispatcher\n",
      "18:35:00 DISPATCHER: job (0, 0, 22) finished\n",
      "18:35:00 DISPATCHER: register_result: lock acquired\n",
      "18:35:00 DISPATCHER: job (0, 0, 22) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:00 job_id: (0, 0, 22)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 27, 'learning_rate': 0.0034632278173121343, 'max_dropout': 0.9764147590757396, 'max_units': 499.74950795995755, 'momentum': 0.5387899813809685, 'num_layers': 1, 'weight_decay': 0.09258801634019763}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -77.74362182617188, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:00 job_callback for (0, 0, 22) started\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:00 job_callback for (0, 0, 22) got condition\n",
      "18:35:00 done building a new model for budget 1.925926 based on 9/19 split\n",
      "Best loss for this budget:-91.828476\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:00 HBMASTER: Trying to run another job!\n",
      "18:35:00 job_callback for (0, 0, 22) finished\n",
      "18:35:00 start sampling a new configuration.\n",
      "18:35:00 best_vector: [0.00013084036941707922, 0.09339086779514502, 0.7561253066636698, 0.2997234441734993, 0.3428552116502275, 0.434618138000129, 0.47820166108757434, 0.0914387630617797], 0.004536444150868037, 4490.417333292324, 20.370527446570414\n",
      "18:35:00 done sampling a new configuration.\n",
      "18:35:00 HBMASTER: schedule new run for iteration 0\n",
      "18:35:00 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "18:35:00 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "18:35:00 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "18:35:00 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:00 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "18:35:00 DISPATCHER: Trying to submit another job.\n",
      "18:35:00 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:00 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:00 WORKER: start processing job (0, 0, 23)\n",
      "18:35:00 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:00 WORKER: args: ()\n",
      "18:35:00 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:01 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 23) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -92.36121368408203, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 23) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 job_callback for (0, 0, 23) got condition\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 done building a new model for budget 1.925926 based on 9/20 split\n",
      "Best loss for this budget:-92.361214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 23) finished\n",
      "18:35:01 start sampling a new configuration.\n",
      "18:35:01 best_vector: [0.006899304497620432, 0.17714682233849507, 0.7210491287018403, 0.015117747090709566, 0.2709809619586826, 0.502394914856468, 0.491420920993877, 0.21845896008852594], 0.003537418030242993, 2.0296804351281314e-07, 7.179828166853696e-10\n",
      "18:35:01 done sampling a new configuration.\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 24) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 24) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 24)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 24) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 WORKER: start processing job (0, 0, 24)\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.014559531021697892, 'max_dropout': 0.015117747090709566, 'max_units': 135.66679496038773, 'momentum': 0.5471314742222566, 'num_layers': 3, 'weight_decay': 0.02185371141925171}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 24), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 24) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 24) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 24) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 24)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.014559531021697892, 'max_dropout': 0.015117747090709566, 'max_units': 135.66679496038773, 'momentum': 0.5471314742222566, 'num_layers': 3, 'weight_decay': 0.02185371141925171}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -90.96929931640625, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 24) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 job_callback for (0, 0, 24) got condition\n",
      "18:35:01 done building a new model for budget 1.925926 based on 9/21 split\n",
      "Best loss for this budget:-92.361214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 24) finished\n",
      "18:35:01 start sampling a new configuration.\n",
      "18:35:01 best_vector: [0.0008893751812438814, 0.18171772225242713, 0.8770568271779366, 0.21509935025711824, 0.11866088341688752, 0.396108028466388, 0.6031396170874272, 0.5861503446457629], 0.003112950245392231, 963.827133462388, 3.0003459116274316\n",
      "18:35:01 done sampling a new configuration.\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 25) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 25) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 25)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 25) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: start processing job (0, 0, 25)\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.04277307581561167, 'max_dropout': 0.21509935025711824, 'max_units': 88.93278951824436, 'momentum': 0.45253614533508535, 'num_layers': 4, 'weight_decay': 0.05861917296112984}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 25), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 25) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 25) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 25) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 25)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.04277307581561167, 'max_dropout': 0.21509935025711824, 'max_units': 88.93278951824436, 'momentum': 0.45253614533508535, 'num_layers': 4, 'weight_decay': 0.05861917296112984}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -89.50213623046875, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 25) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 job_callback for (0, 0, 25) got condition\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 done building a new model for budget 1.925926 based on 9/22 split\n",
      "Best loss for this budget:-92.361214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 25) finished\n",
      "18:35:01 start sampling a new configuration.\n",
      "18:35:01 best_vector: [0.0005118728360776702, 0.16507195093786983, 0.6034128631834232, 0.15578035756628578, 0.09568619741079465, 0.4416034279206257, 0.6308650307631476, 0.7561828933978472], 0.0013428249011500075, 4769.9004117188, 6.405141048861678\n",
      "18:35:01 done sampling a new configuration.\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 WORKER: start processing job (0, 0, 26)\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 28, 'learning_rate': 0.006460090313191405, 'max_dropout': 0.15578035756628578, 'max_units': 83.44448456011497, 'momentum': 0.49302705084935683, 'num_layers': 4, 'weight_decay': 0.07562072751085074}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 26) with dispatcher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:01 DISPATCHER: job (0, 0, 26) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 26) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 28, 'learning_rate': 0.006460090313191405, 'max_dropout': 0.15578035756628578, 'max_units': 83.44448456011497, 'momentum': 0.49302705084935683, 'num_layers': 4, 'weight_decay': 0.07562072751085074}, 'budget': 1.9259259259259258, 'working_directory': '.'}\n",
      "result: {'loss': -88.32975006103516, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 26) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 job_callback for (0, 0, 26) got condition\n",
      "18:35:01 done building a new model for budget 1.925926 based on 9/22 split\n",
      "Best loss for this budget:-92.361214\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 26) finished\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 1) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 10) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 15) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 19) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 21) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 23) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 24) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 25) to next budget 5.777778\n",
      "18:35:01 ITERATION: Advancing config (0, 0, 26) to next budget 5.777778\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: start processing job (0, 0, 1)\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 31, 'learning_rate': 0.08518909658125563, 'max_dropout': 0.3058476368770261, 'max_units': 863.0596531269018, 'momentum': 0.5368413097989411, 'num_layers': 4, 'weight_decay': 0.08674342468960657}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 1) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 1) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 31, 'learning_rate': 0.08518909658125563, 'max_dropout': 0.3058476368770261, 'max_units': 863.0596531269018, 'momentum': 0.5368413097989411, 'num_layers': 4, 'weight_decay': 0.08674342468960657}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -93.98326110839844, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 1) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 job_callback for (0, 0, 1) got condition\n",
      "18:35:01 Only 1 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 1) finished\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 WORKER: start processing job (0, 0, 10)\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 16, 'learning_rate': 0.09965246178024781, 'max_dropout': 0.23067079670548118, 'max_units': 186.01073772788814, 'momentum': 0.41038774349217866, 'num_layers': 3, 'weight_decay': 0.0017807843726372486}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 10) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 10) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 16, 'learning_rate': 0.09965246178024781, 'max_dropout': 0.23067079670548118, 'max_units': 186.01073772788814, 'momentum': 0.41038774349217866, 'num_layers': 3, 'weight_decay': 0.0017807843726372486}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -94.71692657470703, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 10) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 job_callback for (0, 0, 10) got condition\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 Only 2 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 10) finished\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 15) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 15) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 15)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 15) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 WORKER: start processing job (0, 0, 15)\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 22, 'learning_rate': 0.06763257085268942, 'max_dropout': 0.658174270541606, 'max_units': 788.69514310382, 'momentum': 0.4423175410094665, 'num_layers': 3, 'weight_decay': 0.04003082477596873}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 15), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 15) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 15) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 15)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 22, 'learning_rate': 0.06763257085268942, 'max_dropout': 0.658174270541606, 'max_units': 788.69514310382, 'momentum': 0.4423175410094665, 'num_layers': 3, 'weight_decay': 0.04003082477596873}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -93.62403106689453, 'info': 'empty'}\n",
      "exception: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:01 job_callback for (0, 0, 15) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 job_callback for (0, 0, 15) got condition\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 Only 3 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 15) finished\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:01 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "18:35:01 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "18:35:01 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "18:35:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:01 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:01 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:01 WORKER: start processing job (0, 0, 19)\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:01 WORKER: args: ()\n",
      "18:35:01 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 18, 'learning_rate': 0.0028563496186187836, 'max_dropout': 0.9095926139180639, 'max_units': 235.0259346639654, 'momentum': 0.46355590683296066, 'num_layers': 3, 'weight_decay': 0.03296613067337738}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:01 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "18:35:01 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "18:35:01 DISPATCHER: job (0, 0, 19) finished\n",
      "18:35:01 DISPATCHER: register_result: lock acquired\n",
      "18:35:01 DISPATCHER: job (0, 0, 19) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:01 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 18, 'learning_rate': 0.0028563496186187836, 'max_dropout': 0.9095926139180639, 'max_units': 235.0259346639654, 'momentum': 0.46355590683296066, 'num_layers': 3, 'weight_decay': 0.03296613067337738}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -95.26864624023438, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:01 job_callback for (0, 0, 19) started\n",
      "18:35:01 DISPATCHER: Trying to submit another job.\n",
      "18:35:01 job_callback for (0, 0, 19) got condition\n",
      "18:35:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:01 Only 4 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:01 HBMASTER: Trying to run another job!\n",
      "18:35:01 job_callback for (0, 0, 19) finished\n",
      "18:35:01 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 21) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 21) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 21)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 21) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 21)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 24, 'learning_rate': 0.00246922573425061, 'max_dropout': 0.46512243238328044, 'max_units': 668.019646538948, 'momentum': 0.3131072323882354, 'num_layers': 3, 'weight_decay': 0.007535266666833379}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 21), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 21) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 21) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 21) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 21)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 24, 'learning_rate': 0.00246922573425061, 'max_dropout': 0.46512243238328044, 'max_units': 668.019646538948, 'momentum': 0.3131072323882354, 'num_layers': 3, 'weight_decay': 0.007535266666833379}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -94.62561798095703, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 21) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 job_callback for (0, 0, 21) got condition\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 Only 5 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 21) finished\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 23)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -96.1573715209961, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 23) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 job_callback for (0, 0, 23) got condition\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 Only 6 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 23) finished\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 24) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 24) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 24)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 24) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 24)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.014559531021697892, 'max_dropout': 0.015117747090709566, 'max_units': 135.66679496038773, 'momentum': 0.5471314742222566, 'num_layers': 3, 'weight_decay': 0.02185371141925171}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 24), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 24) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 24) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 24) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 24)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.014559531021697892, 'max_dropout': 0.015117747090709566, 'max_units': 135.66679496038773, 'momentum': 0.5471314742222566, 'num_layers': 3, 'weight_decay': 0.02185371141925171}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -95.57042694091797, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 24) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 job_callback for (0, 0, 24) got condition\n",
      "18:35:02 Only 7 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 24) finished\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 25) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 25) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 25)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 25) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: start processing job (0, 0, 25)\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.04277307581561167, 'max_dropout': 0.21509935025711824, 'max_units': 88.93278951824436, 'momentum': 0.45253614533508535, 'num_layers': 4, 'weight_decay': 0.05861917296112984}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 25), trying to register it.\n",
      "18:35:02 DISPATCHER: job (0, 0, 25) finished\n",
      "18:35:02 WORKER: registered result for job (0, 0, 25) with dispatcher\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 25) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 25)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.04277307581561167, 'max_dropout': 0.21509935025711824, 'max_units': 88.93278951824436, 'momentum': 0.45253614533508535, 'num_layers': 4, 'weight_decay': 0.05861917296112984}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -94.41527557373047, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 25) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 job_callback for (0, 0, 25) got condition\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 Only 8 run(s) for budget 5.777778 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 25) finished\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 26)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 28, 'learning_rate': 0.006460090313191405, 'max_dropout': 0.15578035756628578, 'max_units': 83.44448456011497, 'momentum': 0.49302705084935683, 'num_layers': 4, 'weight_decay': 0.07562072751085074}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 26) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 26) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 26) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 28, 'learning_rate': 0.006460090313191405, 'max_dropout': 0.15578035756628578, 'max_units': 83.44448456011497, 'momentum': 0.49302705084935683, 'num_layers': 4, 'weight_decay': 0.07562072751085074}, 'budget': 5.777777777777778, 'working_directory': '.'}\n",
      "result: {'loss': -95.0120849609375, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 26) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 job_callback for (0, 0, 26) got condition\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 26) finished\n",
      "18:35:02 ITERATION: Advancing config (0, 0, 19) to next budget 17.333333\n",
      "18:35:02 ITERATION: Advancing config (0, 0, 23) to next budget 17.333333\n",
      "18:35:02 ITERATION: Advancing config (0, 0, 24) to next budget 17.333333\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 19)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 18, 'learning_rate': 0.0028563496186187836, 'max_dropout': 0.9095926139180639, 'max_units': 235.0259346639654, 'momentum': 0.46355590683296066, 'num_layers': 3, 'weight_decay': 0.03296613067337738}, 'budget': 17.333333333333332, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 19) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 19) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 18, 'learning_rate': 0.0028563496186187836, 'max_dropout': 0.9095926139180639, 'max_units': 235.0259346639654, 'momentum': 0.46355590683296066, 'num_layers': 3, 'weight_decay': 0.03296613067337738}, 'budget': 17.333333333333332, 'working_directory': '.'}\n",
      "result: {'loss': -96.18732452392578, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 19) started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 job_callback for (0, 0, 19) got condition\n",
      "18:35:02 Only 1 run(s) for budget 17.333333 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 19) finished\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 23)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 17.333333333333332, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 17.333333333333332, 'working_directory': '.'}\n",
      "result: {'loss': -96.54300689697266, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 23) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 job_callback for (0, 0, 23) got condition\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 Only 2 run(s) for budget 17.333333 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 23) finished\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 24) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 24) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 24)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 24) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 24)\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.014559531021697892, 'max_dropout': 0.015117747090709566, 'max_units': 135.66679496038773, 'momentum': 0.5471314742222566, 'num_layers': 3, 'weight_decay': 0.02185371141925171}, 'budget': 17.333333333333332, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 24), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 24) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 24) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 24) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 24)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 29, 'learning_rate': 0.014559531021697892, 'max_dropout': 0.015117747090709566, 'max_units': 135.66679496038773, 'momentum': 0.5471314742222566, 'num_layers': 3, 'weight_decay': 0.02185371141925171}, 'budget': 17.333333333333332, 'working_directory': '.'}\n",
      "result: {'loss': -96.15349578857422, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 24) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 job_callback for (0, 0, 24) got condition\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 Only 3 run(s) for budget 17.333333 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 24) finished\n",
      "18:35:02 ITERATION: Advancing config (0, 0, 23) to next budget 52.000000\n",
      "18:35:02 HBMASTER: schedule new run for iteration 0\n",
      "18:35:02 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "18:35:02 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "18:35:02 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "18:35:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "18:35:02 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "18:35:02 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_lcbench.worker.arch.56954140259706070848\n",
      "18:35:02 WORKER: start processing job (0, 0, 23)\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "18:35:02 WORKER: args: ()\n",
      "18:35:02 WORKER: kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 52.0, 'working_directory': '.'}\n",
      "18:35:02 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "18:35:02 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) finished\n",
      "18:35:02 DISPATCHER: register_result: lock acquired\n",
      "18:35:02 DISPATCHER: job (0, 0, 23) on hpbandster.run_lcbench.worker.arch.56954140259706070848 finished\n",
      "18:35:02 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}, 'budget': 52.0, 'working_directory': '.'}\n",
      "result: {'loss': -97.05791473388672, 'info': 'empty'}\n",
      "exception: None\n",
      "\n",
      "18:35:02 job_callback for (0, 0, 23) started\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "18:35:02 job_callback for (0, 0, 23) got condition\n",
      "18:35:02 Only 1 run(s) for budget 52.000000 available, need more than 10 -> can't build model!\n",
      "18:35:02 HBMASTER: Trying to run another job!\n",
      "18:35:02 job_callback for (0, 0, 23) finished\n",
      "18:35:02 HBMASTER: shutdown initiated, shutdown_workers = True\n",
      "18:35:02 WORKER: shutting down now!\n",
      "18:35:02 DISPATCHER: Dispatcher shutting down\n",
      "18:35:02 DISPATCHER: Trying to submit another job.\n",
      "18:35:02 DISPATCHER: job_runner shutting down\n",
      "18:35:02 DISPATCHER: discover_workers shutting down\n",
      "18:35:02 DISPATCHER: 'discover_worker' thread exited\n",
      "18:35:02 DISPATCHER: 'job_runner' thread exited\n",
      "18:35:02 DISPATCHER: shut down complete\n"
     ]
    }
   ],
   "source": [
    "# Initialize the set providing a scenario\n",
    "bench = benchmark_set.BenchmarkSet(\"lcbench\")\n",
    "# Choose an instance\n",
    "bench.set_instance(\"3945\")\n",
    "\n",
    "# Start up the nameserver\n",
    "NS = hpns.NameServer(run_id=\"lcbench\", host=\"127.0.0.1\", port=None)\n",
    "NS.start()\n",
    "\n",
    "# Run BOHB\n",
    "w = lcbench(sleep_interval=0, nameserver=\"127.0.0.1\", run_id =\"lcbench\")\n",
    "w.run(background=True)\n",
    "\n",
    "bohb = BOHB(configspace=w.get_configspace(),\n",
    "            run_id=\"lcbench\", nameserver=\"127.0.0.1\",\n",
    "            min_budget=1, max_budget=52)\n",
    "\n",
    "res = bohb.run(n_iterations=1)\n",
    "\n",
    "bohb.shutdown(shutdown_workers=True)\n",
    "NS.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0,\n",
       "  0,\n",
       "  0): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 74,\n",
       "   'learning_rate': 0.03730364728284649,\n",
       "   'max_dropout': 0.10928899279517446,\n",
       "   'max_units': 352.7361539760635,\n",
       "   'momentum': 0.6132073024377236,\n",
       "   'num_layers': 1,\n",
       "   'weight_decay': 0.04487797472390004}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  1): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 31,\n",
       "   'learning_rate': 0.08518909658125563,\n",
       "   'max_dropout': 0.3058476368770261,\n",
       "   'max_units': 863.0596531269018,\n",
       "   'momentum': 0.5368413097989411,\n",
       "   'num_layers': 4,\n",
       "   'weight_decay': 0.08674342468960657}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  2): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 29,\n",
       "   'learning_rate': 0.00013186846924119304,\n",
       "   'max_dropout': 0.5978682680734122,\n",
       "   'max_units': 408.45051767218047,\n",
       "   'momentum': 0.2511205608534902,\n",
       "   'num_layers': 2,\n",
       "   'weight_decay': 0.00969841062711537}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  3): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 237,\n",
       "   'learning_rate': 0.00024492005087955776,\n",
       "   'max_dropout': 0.9326481248593591,\n",
       "   'max_units': 113.13893756583592,\n",
       "   'momentum': 0.9549199898172877,\n",
       "   'num_layers': 1,\n",
       "   'weight_decay': 0.09036770277766405}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  4): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 78,\n",
       "   'learning_rate': 0.00046605090102701046,\n",
       "   'max_dropout': 0.37760916609240414,\n",
       "   'max_units': 587.3005176686662,\n",
       "   'momentum': 0.6243512031363482,\n",
       "   'num_layers': 1,\n",
       "   'weight_decay': 0.059068870099834976}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  5): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 204,\n",
       "   'learning_rate': 0.0009627007136968641,\n",
       "   'max_dropout': 0.142632116942372,\n",
       "   'max_units': 114.05559626681749,\n",
       "   'momentum': 0.5835428375685867,\n",
       "   'num_layers': 2,\n",
       "   'weight_decay': 0.04777656152782972}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  6): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 159,\n",
       "   'learning_rate': 0.0007794238351845806,\n",
       "   'max_dropout': 0.6177280454429146,\n",
       "   'max_units': 284.36286806012544,\n",
       "   'momentum': 0.5467757478844134,\n",
       "   'num_layers': 4,\n",
       "   'weight_decay': 0.015343310867126706}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  7): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 36,\n",
       "   'learning_rate': 0.00021079792907783103,\n",
       "   'max_dropout': 0.5959221435701585,\n",
       "   'max_units': 240.71839254970942,\n",
       "   'momentum': 0.5984560177688396,\n",
       "   'num_layers': 1,\n",
       "   'weight_decay': 0.035851791962409875}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  8): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 71,\n",
       "   'learning_rate': 0.014713102434385998,\n",
       "   'max_dropout': 0.873979425795715,\n",
       "   'max_units': 824.7270685616847,\n",
       "   'momentum': 0.4719015589397174,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.02998264085755615}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  9): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 19,\n",
       "   'learning_rate': 0.00015449907446589309,\n",
       "   'max_dropout': 0.8804425293712883,\n",
       "   'max_units': 930.1749596596248,\n",
       "   'momentum': 0.5586153493012914,\n",
       "   'num_layers': 2,\n",
       "   'weight_decay': 0.07750174375517623}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  10): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 16,\n",
       "   'learning_rate': 0.09965246178024781,\n",
       "   'max_dropout': 0.23067079670548118,\n",
       "   'max_units': 186.01073772788814,\n",
       "   'momentum': 0.41038774349217866,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.0017807843726372486}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  11): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 39,\n",
       "   'learning_rate': 0.06159566555411365,\n",
       "   'max_dropout': 0.6594305750936577,\n",
       "   'max_units': 387.8333454634667,\n",
       "   'momentum': 0.13364376917889323,\n",
       "   'num_layers': 2,\n",
       "   'weight_decay': 0.03236163152914593}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  12): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 335,\n",
       "   'learning_rate': 0.00011061494140521067,\n",
       "   'max_dropout': 0.9851954432898017,\n",
       "   'max_units': 903.5368553186127,\n",
       "   'momentum': 0.6350123613602908,\n",
       "   'num_layers': 2,\n",
       "   'weight_decay': 0.09060836839847441}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  13): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 86,\n",
       "   'learning_rate': 0.006589518223952934,\n",
       "   'max_dropout': 0.8451177276334075,\n",
       "   'max_units': 205.2164637516088,\n",
       "   'momentum': 0.44951073668224517,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.028528629600967963}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  14): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 26,\n",
       "   'learning_rate': 0.0001700082178346727,\n",
       "   'max_dropout': 0.600748282711434,\n",
       "   'max_units': 151.34593278717193,\n",
       "   'momentum': 0.23535414523187556,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.09830660897204233}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  15): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 22,\n",
       "   'learning_rate': 0.06763257085268942,\n",
       "   'max_dropout': 0.658174270541606,\n",
       "   'max_units': 788.69514310382,\n",
       "   'momentum': 0.4423175410094665,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.04003082477596873}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  16): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 71,\n",
       "   'learning_rate': 0.05256808336132757,\n",
       "   'max_dropout': 0.970224887967548,\n",
       "   'max_units': 333.29107731056337,\n",
       "   'momentum': 0.11127046618091352,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.09916214131942899}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  17): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 89,\n",
       "   'learning_rate': 0.006700784221568951,\n",
       "   'max_dropout': 0.2876804285667456,\n",
       "   'max_units': 641.0028644726066,\n",
       "   'momentum': 0.441791642606282,\n",
       "   'num_layers': 4,\n",
       "   'weight_decay': 0.07588250516594106}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  18): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 104,\n",
       "   'learning_rate': 0.000627729709886735,\n",
       "   'max_dropout': 0.9090119444446737,\n",
       "   'max_units': 549.6576932759838,\n",
       "   'momentum': 0.8602032418902146,\n",
       "   'num_layers': 2,\n",
       "   'weight_decay': 0.03431506731273006}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  19): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 18,\n",
       "   'learning_rate': 0.0028563496186187836,\n",
       "   'max_dropout': 0.9095926139180639,\n",
       "   'max_units': 235.0259346639654,\n",
       "   'momentum': 0.46355590683296066,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.03296613067337738}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  20): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 142,\n",
       "   'learning_rate': 0.05199835635916993,\n",
       "   'max_dropout': 0.647005680388937,\n",
       "   'max_units': 106.99001089522743,\n",
       "   'momentum': 0.328723722606558,\n",
       "   'num_layers': 5,\n",
       "   'weight_decay': 0.09574665904617781}, 'config_info': {'model_based_pick': False}},\n",
       " (0,\n",
       "  0,\n",
       "  21): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 24,\n",
       "   'learning_rate': 0.00246922573425061,\n",
       "   'max_dropout': 0.46512243238328044,\n",
       "   'max_units': 668.019646538948,\n",
       "   'momentum': 0.3131072323882354,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.007535266666833379}, 'config_info': {'model_based_pick': True}},\n",
       " (0,\n",
       "  0,\n",
       "  22): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 27,\n",
       "   'learning_rate': 0.0034632278173121343,\n",
       "   'max_dropout': 0.9764147590757396,\n",
       "   'max_units': 499.74950795995755,\n",
       "   'momentum': 0.5387899813809685,\n",
       "   'num_layers': 1,\n",
       "   'weight_decay': 0.09258801634019763}, 'config_info': {'model_based_pick': True}},\n",
       " (0,\n",
       "  0,\n",
       "  23): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 21,\n",
       "   'learning_rate': 0.018551367122870657,\n",
       "   'max_dropout': 0.2997234441734993,\n",
       "   'max_units': 165.58415856603133,\n",
       "   'momentum': 0.4868101428201148,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.009152961918547352}, 'config_info': {'model_based_pick': True}},\n",
       " (0,\n",
       "  0,\n",
       "  24): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 29,\n",
       "   'learning_rate': 0.014559531021697892,\n",
       "   'max_dropout': 0.015117747090709566,\n",
       "   'max_units': 135.66679496038773,\n",
       "   'momentum': 0.5471314742222566,\n",
       "   'num_layers': 3,\n",
       "   'weight_decay': 0.02185371141925171}, 'config_info': {'model_based_pick': True}},\n",
       " (0,\n",
       "  0,\n",
       "  25): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 29,\n",
       "   'learning_rate': 0.04277307581561167,\n",
       "   'max_dropout': 0.21509935025711824,\n",
       "   'max_units': 88.93278951824436,\n",
       "   'momentum': 0.45253614533508535,\n",
       "   'num_layers': 4,\n",
       "   'weight_decay': 0.05861917296112984}, 'config_info': {'model_based_pick': True}},\n",
       " (0,\n",
       "  0,\n",
       "  26): {'config': {'OpenML_task_id': '3945',\n",
       "   'batch_size': 28,\n",
       "   'learning_rate': 0.006460090313191405,\n",
       "   'max_dropout': 0.15578035756628578,\n",
       "   'max_units': 83.44448456011497,\n",
       "   'momentum': 0.49302705084935683,\n",
       "   'num_layers': 4,\n",
       "   'weight_decay': 0.07562072751085074}, 'config_info': {'model_based_pick': True}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2config = res.get_id2config_mapping()\n",
    "id2config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 23)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incumbent = res.get_incumbent_id()\n",
    "incumbent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found configuration: {'OpenML_task_id': '3945', 'batch_size': 21, 'learning_rate': 0.018551367122870657, 'max_dropout': 0.2997234441734993, 'max_units': 165.58415856603133, 'momentum': 0.4868101428201148, 'num_layers': 3, 'weight_decay': 0.009152961918547352}\n",
      "A total of 27 unique configurations where sampled.\n",
      "A total of 40 runs where executed.\n",
      "Total budget corresponds to 208.0 full function evaluations.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best found configuration:\", id2config[incumbent][\"config\"])\n",
    "print(\"A total of %i unique configurations where sampled.\" % len(id2config.keys()))\n",
    "print(\"A total of %i runs where executed.\" % len(res.get_all_runs()))\n",
    "print(\"Total budget corresponds to %.1f full function evaluations.\"%(sum([r.budget for r in res.get_all_runs()])/1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3cdc79f509a9ca6cc625385dfd789e9f9f8ab6d1f415976660039c24316de9a"
  },
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
